# Sparse 2D Image to 3D Model Reconstruction

This project focuses on reconstructing 3D scenes from sparse 2D images using a hybrid deep learning pipeline. It leverages voxel grids, 3D CNNs, Graph Neural Networks (GNNs), and Neural Radiance Fields (NeRF) to produce accurate 3D mesh representations of outdoor scenes, with data sourced from the KITTI dataset.

## ðŸ§  Motivation

Sparse 2D images are often all we have in real-world driving scenarios. This project addresses the challenge of generating detailed 3D representations from minimal input viewsâ€”critical for autonomous driving, robotics, and scene understanding.

---

## ðŸ“Œ Features

- âœ… Sparse 2D input support (few-view reconstruction)
- âœ… Voxel grid generation from 2D image inputs
- âœ… 3D Convolutional Neural Network for coarse geometry prediction
- âœ… GNN-based refinement of topological structure
- âœ… NeRF module for realistic surface rendering
- âœ… Final output as a textured 3D mesh or point cloud

---


## ðŸ›  Architecture Overview

Sparse 2D Images
â†“
Preprocessing (resize, calibrate)
â†“
Voxel Grid Generation
â†“
3D CNN (Feature Extraction & Coarse Shape)
â†“
Graph Neural Network (Refinement)
â†“
NeRF (Photorealistic Reconstruction)
â†“
3D Mesh / Point Cloud Output

---

## ðŸ“‚ Dataset

- **Source**: [KITTI Vision Benchmark Suite](http://www.cvlibs.net/datasets/kitti/)
- **Preprocessing**: Image resizing, depth-map extraction, camera calibration
- **Split**: Train / Test / Validation (80 / 10 / 10)

---

